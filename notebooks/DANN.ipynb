{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"aGDf5h0LbvjA","executionInfo":{"status":"ok","timestamp":1719588568577,"user_tz":-180,"elapsed":17889,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"outputs":[],"source":["%%capture\n","%pip install torchvision\n","%pip install torchsummary"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/Othercomputers/My Computer/Masters_Staff/trimester_3/Deep_Learning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1wykbi1b_EP","executionInfo":{"status":"ok","timestamp":1719588570867,"user_tz":-180,"elapsed":2292,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"1dfbebe7-ce03-4270-9ddc-c3ef27e241aa"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/Othercomputers/My Computer/Masters_Staff/trimester_3/Deep_Learning\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"cT3SqpBbvt7V"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","import itertools\n","import random\n","import datetime\n","import os\n","\n","\n","\n","from torch.autograd import Function\n","from sklearn.manifold import TSNE\n","from torch.utils.data import DataLoader, Subset\n","from torchsummary import summary\n","from torch.autograd import Variable\n","from torchvision import datasets, transforms\n","from itertools import zip_longest\n","from collections import deque\n"],"metadata":{"id":"32r0XjoxcA_X","executionInfo":{"status":"ok","timestamp":1719588576645,"user_tz":-180,"elapsed":5781,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cloK386fcDT3","executionInfo":{"status":"ok","timestamp":1719588576646,"user_tz":-180,"elapsed":15,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"842a981a-372c-41c7-cabc-babfde6d4823"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Jun 28 15:29:36 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   64C    P8              13W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["#model params\n","params = {\n","    'epochs':30,\n","    'num_workers':4,\n","    'batch_size':32,\n","    'mul': 100,\n","    'num_classes':10,\n","    'channels':3,\n","    'img_dim':32,\n","    'device':torch.device('cuda') if torch.cuda.is_available() else 'cpu',\n","    'fliplr':True,\n","    'num_epochs':50,\n","    'decay_epoch':50,\n","    'lr':0.00002,    #learning rate for generator\n","    'beta1':0.5 ,    #beta1 for Adam optimizer\n","    'beta2':0.999 ,  #beta2 for Adam optimizer\n","    'lambdaA':10 ,   #lambdaA for cycle loss\n","    'lambdaB':10  ,  #lambdaB for cycle loss\n","}\n"],"metadata":{"id":"OJ0UEAW1uq9m","executionInfo":{"status":"ok","timestamp":1719588576646,"user_tz":-180,"elapsed":3,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, Subset\n","import numpy as np\n","from torchvision import datasets, transforms\n","\n","# Function to load and preprocess datasets\n","def load_dataset(dataset_cls, split, root, download, normalize=False, subset_size=None, batch_size=params['batch_size'], transformed=False):\n","    \"\"\"\n","      Load and preprocess a dataset.\n","      :param dataset_cls: Dataset class (e.g., datasets.MNIST, datasets.CIFAR10)\n","      :param split: Data split ('train' or 'test')\n","      :param root: Root directory for dataset storage/download\n","      :param download: Flag to download the dataset if not present\n","      :param normalize: Flag to normalize the dataset\n","      :param subset_size: Size of the subset to use (if specified)\n","      :param batch_size: Batch size for DataLoader\n","      :param transformed: Flag to apply specific transformations\n","      :return: DataLoader object\n","    \"\"\"\n","    if transformed:\n","        transform = transforms.Compose([\n","            transforms.Resize(int(params['img_dim'])),\n","            transforms.Grayscale(params['channels']),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.5]*params['channels'], [0.5]*params['channels'])\n","        ])\n","        dataset = datasets.ImageFolder(root=root, transform=transform)\n","    else:\n","        if dataset_cls == datasets.MNIST or dataset_cls == datasets.USPS:\n","            dataset = dataset_cls(root=root, train=(split=='train'), download=download, transform=transforms.ToTensor())\n","        else:\n","            dataset = dataset_cls(root=root, split=split, download=download, transform=transforms.ToTensor())\n","\n","        if normalize:\n","            if dataset_cls == datasets.MNIST or dataset_cls == datasets.USPS:\n","                print(f\"Dataset is : {dataset_cls}\")\n","                transform = transforms.Compose([\n","                    transforms.Resize(int(params['img_dim'])),\n","                    transforms.Grayscale(params['channels']),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize(mean=[0.5]*params['channels'], std=[0.5]*params['channels'])\n","                ])\n","            else:\n","                print(f\"Dataset is : {dataset_cls}\")\n","                transform = transforms.Compose([\n","                    transforms.Resize(int(params['img_dim'])),\n","                    transforms.Grayscale(params['channels']),\n","                    transforms.ToTensor(),\n","                    transforms.Normalize(mean=[0.5]*params['channels'], std=[0.5]*params['channels'])\n","                ])\n","            # Apply the computed normalization\n","            dataset.transform = transform\n","\n","    if subset_size:\n","        indices = np.random.choice(len(dataset), subset_size, replace=False)\n","        print(dataset.transform)\n","        dataset = Subset(dataset, indices)\n","\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True if split == 'train' else False)\n","    return loader\n","\n","# Load MNIST datasets\n","mnist_trainloader = load_dataset(datasets.MNIST, 'train', './data/', True, normalize=True, subset_size=params['batch_size']*params['mul'])\n","mnist_testloader = load_dataset(datasets.MNIST, 'test', './data/', True, normalize=True)\n","\n","# Load SVHN datasets\n","svhn_trainloader = load_dataset(datasets.SVHN, 'train', './data/', True, normalize=True, subset_size=params['batch_size']*params['mul'])\n","svhn_testloader = load_dataset(datasets.SVHN, 'test', './data/', True, normalize=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7uOgOYnLcEi4","executionInfo":{"status":"ok","timestamp":1719588584130,"user_tz":-180,"elapsed":7486,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"d95c78fc-927f-4958-e4c8-4b8bef6d0ca2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset is : <class 'torchvision.datasets.mnist.MNIST'>\n","Compose(\n","    Resize(size=32, interpolation=bilinear, max_size=None, antialias=True)\n","    Grayscale(num_output_channels=3)\n","    ToTensor()\n","    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",")\n","Dataset is : <class 'torchvision.datasets.mnist.MNIST'>\n","Using downloaded and verified file: ./data/train_32x32.mat\n","Dataset is : <class 'torchvision.datasets.svhn.SVHN'>\n","Compose(\n","    Resize(size=32, interpolation=bilinear, max_size=None, antialias=True)\n","    Grayscale(num_output_channels=3)\n","    ToTensor()\n","    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",")\n","Using downloaded and verified file: ./data/test_32x32.mat\n","Dataset is : <class 'torchvision.datasets.svhn.SVHN'>\n"]}]},{"cell_type":"markdown","source":["### Second Try DANN"],"metadata":{"id":"2iQG_Rl3JBnW"}},{"cell_type":"code","source":["class ReverseLayerF(Function):\n","    \"\"\"\n","      Custom autograd function to create a gradient reversal layer.\n","      This layer is useful in domain adaptation tasks, where gradients are\n","      reversed during the backward pass to train adversarial networks.\n","    \"\"\"\n","\n","    @staticmethod\n","    def forward(ctx, x, alpha):\n","        ctx.alpha = alpha\n","\n","        return x.view_as(x)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        output = grad_output.neg() * ctx.alpha\n","\n","        return output, None\n","\n","\n","def save_model(encoder, classifier, discriminator, training_mode):\n","    print('Saving models ...')\n","    save_folder = 'trained_models'\n","    if not os.path.exists(save_folder):\n","        os.makedirs(save_folder)\n","\n","    torch.save(encoder.state_dict(), 'trained_models/encoder_' + str(training_mode) + '.pt')\n","    torch.save(classifier.state_dict(), 'trained_models/classifier_' + str(training_mode) + '.pt')\n","\n","    if training_mode == 'dann':\n","        torch.save(discriminator.state_dict(), 'trained_models/discriminator_' + str(training_mode) + '.pt')\n","\n","    print('The model has been successfully saved!')\n","\n","\n","def optimizer_scheduler(optimizer, p):\n","    \"\"\"\n","    Adjust the learning rate of optimizer\n","    :param optimizer: optimizer for updating parameters\n","    :param p: a variable for adjusting learning rate\n","    :return: optimizer\n","    \"\"\"\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = 0.01 / (1. + 10 * p) ** 0.75\n","\n","    return optimizer\n","\n","\n","def set_model_mode(mode='train', models=None):\n","    for model in models:\n","        if mode == 'train':\n","            model.train()\n","        else:\n","            model.eval()\n","\n","class Extractor(nn.Module):\n","    def __init__(self):\n","        super(Extractor, self).__init__()\n","        self.extractor = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2),\n","\n","            nn.Conv2d(in_channels=32, out_channels=48, kernel_size=5, padding=2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","\n","    def forward(self, x):\n","        x = self.extractor(x)\n","        x = x.view(-1, 3 * 32 * 32)\n","        return x\n","\n","\n","class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Linear(in_features=3 * 32 * 32, out_features=100),\n","            nn.ReLU(),\n","            nn.Linear(in_features=100, out_features=100),\n","            nn.ReLU(),\n","            nn.Linear(in_features=100, out_features=10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.classifier(x)\n","        return x\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.discriminator = nn.Sequential(\n","            nn.Linear(in_features=3 * 32 * 32, out_features=100),\n","            nn.ReLU(),\n","            nn.Linear(in_features=100, out_features=2)\n","        )\n","\n","    def forward(self, input_feature, alpha):\n","        reversed_input = ReverseLayerF.apply(input_feature, alpha)\n","        x = self.discriminator(reversed_input)\n","        return x"],"metadata":{"id":"WJtWYYcaPgLO","executionInfo":{"status":"ok","timestamp":1719588584130,"user_tz":-180,"elapsed":12,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","\n","\n","def tester(encoder, classifier, discriminator, source_test_loader, target_test_loader, training_mode):\n","    \"\"\"\n","      Test the models.\n","      :param encoder: Encoder model\n","      :param classifier: Classifier model\n","      :param discriminator: Discriminator model (for DANN)\n","      :param source_test_loader: DataLoader for source test data\n","      :param target_test_loader: DataLoader for target test data\n","      :param training_mode: Training mode ('DANN' or other)\n","      :return: None\n","    \"\"\"\n","    encoder.cuda()\n","    classifier.cuda()\n","    set_model_mode('eval', [encoder, classifier])\n","\n","    if training_mode == 'DANN':\n","        discriminator.cuda()\n","        set_model_mode('eval', [discriminator])\n","        domain_correct = 0\n","\n","    source_correct = 0\n","    target_correct = 0\n","\n","    for batch_idx, (source_data, target_data) in enumerate(zip(source_test_loader, target_test_loader)):\n","        p = float(batch_idx) / len(source_test_loader)\n","        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n","\n","        # Process source and target data\n","        source_image, source_label = process_data(source_data, expand_channels=False)\n","        target_image, target_label = process_data(target_data)\n","\n","        # Compute source and target predictions\n","        source_pred = compute_output(encoder, classifier, source_image, alpha=None)\n","        target_pred = compute_output(encoder, classifier, target_image, alpha=None)\n","\n","        # Update correct counts\n","        source_correct += source_pred.eq(source_label.data.view_as(source_pred)).sum().item()\n","        target_correct += target_pred.eq(target_label.data.view_as(target_pred)).sum().item()\n","\n","        if training_mode == 'DANN':\n","            # Process combined images for domain classification\n","            combined_image = torch.cat((source_image, target_image), 0)\n","            domain_labels = torch.cat((torch.zeros(source_label.size(0), dtype=torch.long),\n","                                       torch.ones(target_label.size(0), dtype=torch.long)), 0).cuda()\n","\n","            # Compute domain predictions\n","            domain_pred = compute_output(encoder, discriminator, combined_image, alpha=alpha)\n","            domain_correct += domain_pred.eq(domain_labels.data.view_as(domain_pred)).sum().item()\n","\n","    source_dataset_len = len(source_test_loader.dataset)\n","    target_dataset_len = len(target_test_loader.dataset)\n","\n","    accuracies = {\n","        \"Source\": {\n","            \"correct\": source_correct,\n","            \"total\": source_dataset_len,\n","            \"accuracy\": calculate_accuracy(source_correct, source_dataset_len)\n","        },\n","        \"Target\": {\n","            \"correct\": target_correct,\n","            \"total\": target_dataset_len,\n","            \"accuracy\": calculate_accuracy(target_correct, target_dataset_len)\n","        }\n","    }\n","\n","    if training_mode == 'DANN':\n","        accuracies[\"Domain\"] = {\n","            \"correct\": domain_correct,\n","            \"total\": source_dataset_len + target_dataset_len,\n","            \"accuracy\": calculate_accuracy(domain_correct, source_dataset_len + target_dataset_len)\n","        }\n","\n","    print_accuracy(training_mode, accuracies)\n","\n","\n","def process_data(data, expand_channels=False):\n","    images, labels = data\n","    images, labels = images.cuda(), labels.cuda()\n","    if expand_channels:\n","        images = images.repeat(1, 3, 1, 1)  # Repeat channels to convert to 3-channel images\n","    return images, labels\n","\n","\n","def compute_output(encoder, classifier, images, alpha=None):\n","    features = encoder(images)\n","    if isinstance(classifier, Discriminator):\n","        outputs = classifier(features, alpha)  # Domain classifier\n","    else:\n","        outputs = classifier(features)  # Category classifier\n","    preds = outputs.data.max(1, keepdim=True)[1]\n","    return preds\n","\n","\n","def calculate_accuracy(correct, total):\n","    return 100. * correct / total\n","\n","\n","def print_accuracy(training_mode, accuracies):\n","    print(f\"Test Results on {training_mode}:\")\n","    for key, value in accuracies.items():\n","        print(f\"{key} Accuracy: {value['correct']}/{value['total']} ({value['accuracy']:.2f}%)\")"],"metadata":{"id":"05npq5_HRVV3","executionInfo":{"status":"ok","timestamp":1719588584130,"user_tz":-180,"elapsed":12,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Source : 0, Target :1\n","source_test_loader =  mnist_testloader\n","target_test_loader = svhn_testloader\n","\n","def source_only(encoder, classifier, source_train_loader, target_train_loader):\n","    \"\"\"\n","      Train using only the source dataset.\n","      :param encoder: Encoder model\n","      :param classifier: Classifier model\n","      :param source_train_loader: DataLoader for source training data\n","      :param target_train_loader: DataLoader for target training data\n","      :return: None\n","    \"\"\"\n","    print(\"Training with only the source dataset\")\n","\n","    classifier_criterion = nn.CrossEntropyLoss().cuda()\n","    optimizer = optim.SGD(\n","        list(encoder.parameters()) +\n","        list(classifier.parameters()),\n","        lr=0.01, momentum=0.9)\n","\n","    for epoch in range(params['epochs']):\n","        print(f\"Epoch: {epoch}\")\n","        set_model_mode('train', [encoder, classifier])\n","\n","        start_steps = epoch * len(source_train_loader)\n","        total_steps = params['epochs'] * len(target_train_loader)\n","\n","        for batch_idx, (source_data, target_data) in enumerate(zip(source_train_loader, target_train_loader)):\n","            source_image, source_label = source_data\n","            p = float(batch_idx + start_steps) / total_steps\n","\n","            # source_image = torch.cat((source_image, source_image, source_image), 1)  # MNIST convert to 3 channel\n","            source_image, source_label = source_image.cuda(), source_label.cuda()  # 32\n","\n","            optimizer = optimizer_scheduler(optimizer=optimizer, p=p)\n","            optimizer.zero_grad()\n","\n","            source_feature = encoder(source_image)\n","\n","            # Classification loss\n","            class_pred = classifier(source_feature)\n","            class_loss = classifier_criterion(class_pred, source_label)\n","\n","            class_loss.backward()\n","            optimizer.step()\n","            if (batch_idx + 1) % 100 == 0:\n","                total_processed = batch_idx * len(source_image)\n","                total_dataset = len(source_train_loader.dataset)\n","                percentage_completed = 100. * batch_idx / len(source_train_loader)\n","                print(f'[{total_processed}/{total_dataset} ({percentage_completed:.0f}%)]\\tClassification Loss: {class_loss.item():.4f}')\n","\n","        tester(encoder, classifier, None, source_test_loader, target_test_loader, training_mode='Source_only')\n","\n","    save_model(encoder, classifier, None, 'Source-only')\n","\n","\n","def dann(encoder, classifier, discriminator, source_train_loader, target_train_loader):\n","    \"\"\"\n","      Train using DANN adaptation method.\n","      :param encoder: Encoder model\n","      :param classifier: Classifier model\n","      :param discriminator: Discriminator model\n","      :param source_train_loader: DataLoader for source training data\n","      :param target_train_loader: DataLoader for target training data\n","      :return: None\n","    \"\"\"\n","    print(\"Training with the DANN adaptation method\")\n","\n","    classifier_criterion = nn.CrossEntropyLoss().cuda()\n","    discriminator_criterion = nn.CrossEntropyLoss().cuda()\n","\n","    optimizer = optim.SGD(\n","        list(encoder.parameters()) +\n","        list(classifier.parameters()) +\n","        list(discriminator.parameters()),\n","        lr=0.01,\n","        momentum=0.9)\n","\n","    for epoch in range(params['epochs']):\n","        print(f\"Epoch: {epoch}\")\n","        set_model_mode('train', [encoder, classifier, discriminator])\n","\n","        start_steps = epoch * len(source_train_loader)\n","        total_steps = params['epochs'] * len(target_train_loader)\n","\n","        for batch_idx, (source_data, target_data) in enumerate(zip(source_train_loader, target_train_loader)):\n","\n","            source_image, source_label = source_data\n","            target_image, target_label = target_data\n","\n","            p = float(batch_idx + start_steps) / total_steps\n","            alpha = 2. / (1. + np.exp(-10 * p)) - 1\n","\n","            source_image, source_label = source_image.cuda(), source_label.cuda()\n","            target_image, target_label = target_image.cuda(), target_label.cuda()\n","            combined_image = torch.cat((source_image, target_image), 0)\n","\n","            optimizer = optimizer_scheduler(optimizer=optimizer, p=p)\n","            optimizer.zero_grad()\n","\n","            combined_feature = encoder(combined_image)\n","            source_feature = encoder(source_image)\n","\n","            # 1.Classification loss\n","            class_pred = classifier(source_feature)\n","            class_loss = classifier_criterion(class_pred, source_label)\n","\n","            # 2. Domain loss\n","            domain_pred = discriminator(combined_feature, alpha)\n","\n","            domain_source_labels = torch.zeros(source_label.shape[0]).type(torch.LongTensor)\n","            domain_target_labels = torch.ones(target_label.shape[0]).type(torch.LongTensor)\n","            domain_combined_label = torch.cat((domain_source_labels, domain_target_labels), 0).cuda()\n","            domain_loss = discriminator_criterion(domain_pred, domain_combined_label)\n","\n","            total_loss = class_loss + domain_loss\n","            total_loss.backward()\n","            optimizer.step()\n","\n","            if (batch_idx + 1) % 100 == 0:\n","                print('[{}/{} ({:.0f}%)]\\tTotal Loss: {:.4f}\\tClassification Loss: {:.4f}\\tDomain Loss: {:.4f}'.format(\n","                    batch_idx * len(target_image), len(target_train_loader.dataset), 100. * batch_idx / len(target_train_loader), total_loss.item(), class_loss.item(), domain_loss.item()))\n","\n","        tester(encoder, classifier, discriminator, source_test_loader, target_test_loader, training_mode='DANN')\n","\n","    save_model(encoder, classifier, discriminator, 'DANN')\n"],"metadata":{"id":"fWUHpHLWQz65","executionInfo":{"status":"ok","timestamp":1719588584130,"user_tz":-180,"elapsed":11,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["source_train_loader = mnist_trainloader\n","target_train_loader = svhn_trainloader\n","\n","if torch.cuda.is_available():\n","    encoder = Extractor().cuda()\n","    classifier = Classifier().cuda()\n","    discriminator = Discriminator().cuda()\n","\n","    source_only(encoder, classifier, source_train_loader, target_train_loader)\n","    dann(encoder, classifier, discriminator, source_train_loader, target_train_loader)\n","else:\n","    print(\"No GPUs available.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBVAyU7qRi-0","executionInfo":{"status":"ok","timestamp":1719589280055,"user_tz":-180,"elapsed":695936,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"5959bf34-7104-489f-ac23-48fb7fdde415"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with only the source dataset\n","Epoch: 0\n","[3168/3200 (99%)]\tClassification Loss: 0.4371\n","Test Results on Source_only:\n","Source Accuracy: 8062/10000 (80.62%)\n","Target Accuracy: 1105/26032 (4.24%)\n","Epoch: 1\n","[3168/3200 (99%)]\tClassification Loss: 0.3374\n","Test Results on Source_only:\n","Source Accuracy: 9455/10000 (94.55%)\n","Target Accuracy: 1947/26032 (7.48%)\n","Epoch: 2\n","[3168/3200 (99%)]\tClassification Loss: 0.2285\n","Test Results on Source_only:\n","Source Accuracy: 9569/10000 (95.69%)\n","Target Accuracy: 2209/26032 (8.49%)\n","Epoch: 3\n","[3168/3200 (99%)]\tClassification Loss: 0.0785\n","Test Results on Source_only:\n","Source Accuracy: 9689/10000 (96.89%)\n","Target Accuracy: 2495/26032 (9.58%)\n","Epoch: 4\n","[3168/3200 (99%)]\tClassification Loss: 0.0358\n","Test Results on Source_only:\n","Source Accuracy: 9679/10000 (96.79%)\n","Target Accuracy: 2432/26032 (9.34%)\n","Epoch: 5\n","[3168/3200 (99%)]\tClassification Loss: 0.0952\n","Test Results on Source_only:\n","Source Accuracy: 9717/10000 (97.17%)\n","Target Accuracy: 2617/26032 (10.05%)\n","Epoch: 6\n","[3168/3200 (99%)]\tClassification Loss: 0.0189\n","Test Results on Source_only:\n","Source Accuracy: 9719/10000 (97.19%)\n","Target Accuracy: 2586/26032 (9.93%)\n","Epoch: 7\n","[3168/3200 (99%)]\tClassification Loss: 0.0103\n","Test Results on Source_only:\n","Source Accuracy: 9770/10000 (97.70%)\n","Target Accuracy: 2621/26032 (10.07%)\n","Epoch: 8\n","[3168/3200 (99%)]\tClassification Loss: 0.0122\n","Test Results on Source_only:\n","Source Accuracy: 9717/10000 (97.17%)\n","Target Accuracy: 2621/26032 (10.07%)\n","Epoch: 9\n","[3168/3200 (99%)]\tClassification Loss: 0.0030\n","Test Results on Source_only:\n","Source Accuracy: 9735/10000 (97.35%)\n","Target Accuracy: 2572/26032 (9.88%)\n","Epoch: 10\n","[3168/3200 (99%)]\tClassification Loss: 0.0046\n","Test Results on Source_only:\n","Source Accuracy: 9756/10000 (97.56%)\n","Target Accuracy: 2773/26032 (10.65%)\n","Epoch: 11\n","[3168/3200 (99%)]\tClassification Loss: 0.0105\n","Test Results on Source_only:\n","Source Accuracy: 9769/10000 (97.69%)\n","Target Accuracy: 2731/26032 (10.49%)\n","Epoch: 12\n","[3168/3200 (99%)]\tClassification Loss: 0.0012\n","Test Results on Source_only:\n","Source Accuracy: 9766/10000 (97.66%)\n","Target Accuracy: 2781/26032 (10.68%)\n","Epoch: 13\n","[3168/3200 (99%)]\tClassification Loss: 0.0076\n","Test Results on Source_only:\n","Source Accuracy: 9759/10000 (97.59%)\n","Target Accuracy: 2609/26032 (10.02%)\n","Epoch: 14\n","[3168/3200 (99%)]\tClassification Loss: 0.0049\n","Test Results on Source_only:\n","Source Accuracy: 9770/10000 (97.70%)\n","Target Accuracy: 2652/26032 (10.19%)\n","Epoch: 15\n","[3168/3200 (99%)]\tClassification Loss: 0.0035\n","Test Results on Source_only:\n","Source Accuracy: 9764/10000 (97.64%)\n","Target Accuracy: 2711/26032 (10.41%)\n","Epoch: 16\n","[3168/3200 (99%)]\tClassification Loss: 0.0006\n","Test Results on Source_only:\n","Source Accuracy: 9769/10000 (97.69%)\n","Target Accuracy: 2724/26032 (10.46%)\n","Epoch: 17\n","[3168/3200 (99%)]\tClassification Loss: 0.0022\n","Test Results on Source_only:\n","Source Accuracy: 9781/10000 (97.81%)\n","Target Accuracy: 2687/26032 (10.32%)\n","Epoch: 18\n","[3168/3200 (99%)]\tClassification Loss: 0.0003\n","Test Results on Source_only:\n","Source Accuracy: 9774/10000 (97.74%)\n","Target Accuracy: 2709/26032 (10.41%)\n","Epoch: 19\n","[3168/3200 (99%)]\tClassification Loss: 0.0013\n","Test Results on Source_only:\n","Source Accuracy: 9773/10000 (97.73%)\n","Target Accuracy: 2709/26032 (10.41%)\n","Epoch: 20\n","[3168/3200 (99%)]\tClassification Loss: 0.0036\n","Test Results on Source_only:\n","Source Accuracy: 9773/10000 (97.73%)\n","Target Accuracy: 2692/26032 (10.34%)\n","Epoch: 21\n","[3168/3200 (99%)]\tClassification Loss: 0.0028\n","Test Results on Source_only:\n","Source Accuracy: 9771/10000 (97.71%)\n","Target Accuracy: 2697/26032 (10.36%)\n","Epoch: 22\n","[3168/3200 (99%)]\tClassification Loss: 0.0003\n","Test Results on Source_only:\n","Source Accuracy: 9772/10000 (97.72%)\n","Target Accuracy: 2680/26032 (10.30%)\n","Epoch: 23\n","[3168/3200 (99%)]\tClassification Loss: 0.0006\n","Test Results on Source_only:\n","Source Accuracy: 9773/10000 (97.73%)\n","Target Accuracy: 2673/26032 (10.27%)\n","Epoch: 24\n","[3168/3200 (99%)]\tClassification Loss: 0.0003\n","Test Results on Source_only:\n","Source Accuracy: 9764/10000 (97.64%)\n","Target Accuracy: 2673/26032 (10.27%)\n","Epoch: 25\n","[3168/3200 (99%)]\tClassification Loss: 0.0008\n","Test Results on Source_only:\n","Source Accuracy: 9770/10000 (97.70%)\n","Target Accuracy: 2697/26032 (10.36%)\n","Epoch: 26\n","[3168/3200 (99%)]\tClassification Loss: 0.0007\n","Test Results on Source_only:\n","Source Accuracy: 9771/10000 (97.71%)\n","Target Accuracy: 2709/26032 (10.41%)\n","Epoch: 27\n","[3168/3200 (99%)]\tClassification Loss: 0.0009\n","Test Results on Source_only:\n","Source Accuracy: 9773/10000 (97.73%)\n","Target Accuracy: 2693/26032 (10.34%)\n","Epoch: 28\n","[3168/3200 (99%)]\tClassification Loss: 0.0025\n","Test Results on Source_only:\n","Source Accuracy: 9774/10000 (97.74%)\n","Target Accuracy: 2696/26032 (10.36%)\n","Epoch: 29\n","[3168/3200 (99%)]\tClassification Loss: 0.0004\n","Test Results on Source_only:\n","Source Accuracy: 9773/10000 (97.73%)\n","Target Accuracy: 2680/26032 (10.30%)\n","Saving models ...\n","The model has been successfully saved!\n","Training with the DANN adaptation method\n","Epoch: 0\n","[3168/3200 (99%)]\tTotal Loss: 0.0172\tClassification Loss: 0.0076\tDomain Loss: 0.0096\n","Test Results on DANN:\n","Source Accuracy: 9722/10000 (97.22%)\n","Target Accuracy: 2734/26032 (10.50%)\n","Domain Accuracy: 19820/36032 (55.01%)\n","Epoch: 1\n","[3168/3200 (99%)]\tTotal Loss: 0.0130\tClassification Loss: 0.0085\tDomain Loss: 0.0046\n","Test Results on DANN:\n","Source Accuracy: 9680/10000 (96.80%)\n","Target Accuracy: 2525/26032 (9.70%)\n","Domain Accuracy: 19884/36032 (55.18%)\n","Epoch: 2\n","[3168/3200 (99%)]\tTotal Loss: 0.0174\tClassification Loss: 0.0126\tDomain Loss: 0.0048\n","Test Results on DANN:\n","Source Accuracy: 9692/10000 (96.92%)\n","Target Accuracy: 2430/26032 (9.33%)\n","Domain Accuracy: 19899/36032 (55.23%)\n","Epoch: 3\n","[3168/3200 (99%)]\tTotal Loss: 0.0102\tClassification Loss: 0.0005\tDomain Loss: 0.0096\n","Test Results on DANN:\n","Source Accuracy: 9764/10000 (97.64%)\n","Target Accuracy: 2689/26032 (10.33%)\n","Domain Accuracy: 19850/36032 (55.09%)\n","Epoch: 4\n","[3168/3200 (99%)]\tTotal Loss: 0.0075\tClassification Loss: 0.0043\tDomain Loss: 0.0032\n","Test Results on DANN:\n","Source Accuracy: 9760/10000 (97.60%)\n","Target Accuracy: 2520/26032 (9.68%)\n","Domain Accuracy: 19833/36032 (55.04%)\n","Epoch: 5\n","[3168/3200 (99%)]\tTotal Loss: 0.0106\tClassification Loss: 0.0050\tDomain Loss: 0.0057\n","Test Results on DANN:\n","Source Accuracy: 9779/10000 (97.79%)\n","Target Accuracy: 2624/26032 (10.08%)\n","Domain Accuracy: 19850/36032 (55.09%)\n","Epoch: 6\n","[3168/3200 (99%)]\tTotal Loss: 0.0368\tClassification Loss: 0.0007\tDomain Loss: 0.0361\n","Test Results on DANN:\n","Source Accuracy: 9775/10000 (97.75%)\n","Target Accuracy: 2614/26032 (10.04%)\n","Domain Accuracy: 19834/36032 (55.05%)\n","Epoch: 7\n","[3168/3200 (99%)]\tTotal Loss: 0.0287\tClassification Loss: 0.0042\tDomain Loss: 0.0245\n","Test Results on DANN:\n","Source Accuracy: 9773/10000 (97.73%)\n","Target Accuracy: 2622/26032 (10.07%)\n","Domain Accuracy: 19872/36032 (55.15%)\n","Epoch: 8\n","[3168/3200 (99%)]\tTotal Loss: 0.0241\tClassification Loss: 0.0018\tDomain Loss: 0.0224\n","Test Results on DANN:\n","Source Accuracy: 9763/10000 (97.63%)\n","Target Accuracy: 2548/26032 (9.79%)\n","Domain Accuracy: 19875/36032 (55.16%)\n","Epoch: 9\n","[3168/3200 (99%)]\tTotal Loss: 0.0142\tClassification Loss: 0.0005\tDomain Loss: 0.0137\n","Test Results on DANN:\n","Source Accuracy: 9760/10000 (97.60%)\n","Target Accuracy: 2543/26032 (9.77%)\n","Domain Accuracy: 19875/36032 (55.16%)\n","Epoch: 10\n","[3168/3200 (99%)]\tTotal Loss: 0.0181\tClassification Loss: 0.0009\tDomain Loss: 0.0172\n","Test Results on DANN:\n","Source Accuracy: 9756/10000 (97.56%)\n","Target Accuracy: 2506/26032 (9.63%)\n","Domain Accuracy: 19871/36032 (55.15%)\n","Epoch: 11\n","[3168/3200 (99%)]\tTotal Loss: 0.0127\tClassification Loss: 0.0055\tDomain Loss: 0.0072\n","Test Results on DANN:\n","Source Accuracy: 9758/10000 (97.58%)\n","Target Accuracy: 2552/26032 (9.80%)\n","Domain Accuracy: 19882/36032 (55.18%)\n","Epoch: 12\n","[3168/3200 (99%)]\tTotal Loss: 0.0096\tClassification Loss: 0.0026\tDomain Loss: 0.0070\n","Test Results on DANN:\n","Source Accuracy: 9756/10000 (97.56%)\n","Target Accuracy: 2538/26032 (9.75%)\n","Domain Accuracy: 19870/36032 (55.15%)\n","Epoch: 13\n","[3168/3200 (99%)]\tTotal Loss: 0.0126\tClassification Loss: 0.0042\tDomain Loss: 0.0084\n","Test Results on DANN:\n","Source Accuracy: 9750/10000 (97.50%)\n","Target Accuracy: 2537/26032 (9.75%)\n","Domain Accuracy: 19882/36032 (55.18%)\n","Epoch: 14\n","[3168/3200 (99%)]\tTotal Loss: 0.0043\tClassification Loss: 0.0009\tDomain Loss: 0.0034\n","Test Results on DANN:\n","Source Accuracy: 9756/10000 (97.56%)\n","Target Accuracy: 2534/26032 (9.73%)\n","Domain Accuracy: 19879/36032 (55.17%)\n","Epoch: 15\n","[3168/3200 (99%)]\tTotal Loss: 0.0107\tClassification Loss: 0.0025\tDomain Loss: 0.0081\n","Test Results on DANN:\n","Source Accuracy: 9755/10000 (97.55%)\n","Target Accuracy: 2532/26032 (9.73%)\n","Domain Accuracy: 19871/36032 (55.15%)\n","Epoch: 16\n","[3168/3200 (99%)]\tTotal Loss: 0.0055\tClassification Loss: 0.0018\tDomain Loss: 0.0037\n","Test Results on DANN:\n","Source Accuracy: 9757/10000 (97.57%)\n","Target Accuracy: 2522/26032 (9.69%)\n","Domain Accuracy: 19877/36032 (55.16%)\n","Epoch: 17\n","[3168/3200 (99%)]\tTotal Loss: 0.0088\tClassification Loss: 0.0001\tDomain Loss: 0.0087\n","Test Results on DANN:\n","Source Accuracy: 9757/10000 (97.57%)\n","Target Accuracy: 2516/26032 (9.67%)\n","Domain Accuracy: 19880/36032 (55.17%)\n","Epoch: 18\n","[3168/3200 (99%)]\tTotal Loss: 0.0038\tClassification Loss: 0.0006\tDomain Loss: 0.0032\n","Test Results on DANN:\n","Source Accuracy: 9753/10000 (97.53%)\n","Target Accuracy: 2518/26032 (9.67%)\n","Domain Accuracy: 19876/36032 (55.16%)\n","Epoch: 19\n","[3168/3200 (99%)]\tTotal Loss: 0.0062\tClassification Loss: 0.0017\tDomain Loss: 0.0045\n","Test Results on DANN:\n","Source Accuracy: 9756/10000 (97.56%)\n","Target Accuracy: 2535/26032 (9.74%)\n","Domain Accuracy: 19876/36032 (55.16%)\n","Epoch: 20\n","[3168/3200 (99%)]\tTotal Loss: 0.0041\tClassification Loss: 0.0006\tDomain Loss: 0.0036\n","Test Results on DANN:\n","Source Accuracy: 9753/10000 (97.53%)\n","Target Accuracy: 2532/26032 (9.73%)\n","Domain Accuracy: 19871/36032 (55.15%)\n","Epoch: 21\n","[3168/3200 (99%)]\tTotal Loss: 0.0054\tClassification Loss: 0.0014\tDomain Loss: 0.0040\n","Test Results on DANN:\n","Source Accuracy: 9758/10000 (97.58%)\n","Target Accuracy: 2528/26032 (9.71%)\n","Domain Accuracy: 19868/36032 (55.14%)\n","Epoch: 22\n","[3168/3200 (99%)]\tTotal Loss: 0.0048\tClassification Loss: 0.0005\tDomain Loss: 0.0043\n","Test Results on DANN:\n","Source Accuracy: 9753/10000 (97.53%)\n","Target Accuracy: 2516/26032 (9.67%)\n","Domain Accuracy: 19861/36032 (55.12%)\n","Epoch: 23\n","[3168/3200 (99%)]\tTotal Loss: 0.0034\tClassification Loss: 0.0011\tDomain Loss: 0.0023\n","Test Results on DANN:\n","Source Accuracy: 9754/10000 (97.54%)\n","Target Accuracy: 2518/26032 (9.67%)\n","Domain Accuracy: 19862/36032 (55.12%)\n","Epoch: 24\n","[3168/3200 (99%)]\tTotal Loss: 0.0093\tClassification Loss: 0.0002\tDomain Loss: 0.0090\n","Test Results on DANN:\n","Source Accuracy: 9755/10000 (97.55%)\n","Target Accuracy: 2520/26032 (9.68%)\n","Domain Accuracy: 19859/36032 (55.11%)\n","Epoch: 25\n","[3168/3200 (99%)]\tTotal Loss: 0.0023\tClassification Loss: 0.0002\tDomain Loss: 0.0022\n","Test Results on DANN:\n","Source Accuracy: 9754/10000 (97.54%)\n","Target Accuracy: 2501/26032 (9.61%)\n","Domain Accuracy: 19858/36032 (55.11%)\n","Epoch: 26\n","[3168/3200 (99%)]\tTotal Loss: 0.0040\tClassification Loss: 0.0014\tDomain Loss: 0.0026\n","Test Results on DANN:\n","Source Accuracy: 9756/10000 (97.56%)\n","Target Accuracy: 2503/26032 (9.62%)\n","Domain Accuracy: 19858/36032 (55.11%)\n","Epoch: 27\n","[3168/3200 (99%)]\tTotal Loss: 0.0057\tClassification Loss: 0.0031\tDomain Loss: 0.0026\n","Test Results on DANN:\n","Source Accuracy: 9758/10000 (97.58%)\n","Target Accuracy: 2489/26032 (9.56%)\n","Domain Accuracy: 19856/36032 (55.11%)\n","Epoch: 28\n","[3168/3200 (99%)]\tTotal Loss: 0.0043\tClassification Loss: 0.0017\tDomain Loss: 0.0026\n","Test Results on DANN:\n","Source Accuracy: 9755/10000 (97.55%)\n","Target Accuracy: 2481/26032 (9.53%)\n","Domain Accuracy: 19854/36032 (55.10%)\n","Epoch: 29\n","[3168/3200 (99%)]\tTotal Loss: 0.0075\tClassification Loss: 0.0012\tDomain Loss: 0.0063\n","Test Results on DANN:\n","Source Accuracy: 9755/10000 (97.55%)\n","Target Accuracy: 2477/26032 (9.52%)\n","Domain Accuracy: 19849/36032 (55.09%)\n","Saving models ...\n","The model has been successfully saved!\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"o2fbgZ-L0o7G","executionInfo":{"status":"ok","timestamp":1719589280055,"user_tz":-180,"elapsed":13,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":10,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}