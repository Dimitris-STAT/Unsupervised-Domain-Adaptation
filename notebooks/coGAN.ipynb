{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5EZxxpaIWRy-","executionInfo":{"status":"ok","timestamp":1718892420220,"user_tz":-180,"elapsed":73514,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"outputs":[],"source":["%%capture\n","%pip install torchvision\n","%pip install torchsummary\n","%pip install torchviz\n","%pip install hiddenlayer"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-gSp91NWRzA","executionInfo":{"status":"ok","timestamp":1718892444610,"user_tz":-180,"elapsed":24392,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"a32e46a3-c526-43d1-84a3-a0f086a52ab4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Othercomputers/My Computer/Masters_Staff/trimester_3/Deep_Learning\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/Othercomputers/My Computer/Masters_Staff/trimester_3/Deep_Learning"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"GY1rE5VnWRzB","executionInfo":{"status":"ok","timestamp":1718892449811,"user_tz":-180,"elapsed":5203,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Subset\n","from torchsummary import summary\n","from torch.autograd import Variable\n","from torchvision import datasets, transforms\n","\n","from torchvision.utils import save_image"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDX4WsemWRzB","executionInfo":{"status":"ok","timestamp":1718892449811,"user_tz":-180,"elapsed":4,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"4c0bff8e-2d84-4340-f72b-45109f21ed28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Jun 20 14:07:30 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"isjiP76yWRzC","executionInfo":{"status":"ok","timestamp":1718895484228,"user_tz":-180,"elapsed":436,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"outputs":[],"source":["#model params\n","params = {\n","    'batch_size':32,\n","    'latent_dim': 100,\n","    'mul': 100,\n","    'num_classes':10,\n","    'channels':3,\n","    'img_size':32,\n","    'device':torch.device('cuda') if torch.cuda.is_available() else 'cpu',\n","    'fliplr':True,\n","    'num_epochs':50,\n","    'decay_epoch':50,\n","    'lr':0.0002,    #learning rate for generator\n","    'b1':0.5 ,    #beta1 for Adam optimizer\n","    'b2':0.999 ,  #beta2 for Adam optimizer\n","    'sample_interval':400,\n","    'n_cpu':8\n","}\n","\n","cuda = True if torch.cuda.is_available() else False"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UiAncgJlWRzC","executionInfo":{"status":"ok","timestamp":1718895489436,"user_tz":-180,"elapsed":3437,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"bde1228f-a18e-4db6-8917-74e3cf04ff28"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset is MNIST: <class 'torchvision.datasets.mnist.MNIST'>\n","Compose(\n","    Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)\n","    Grayscale(num_output_channels=3)\n","    ToTensor()\n","    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",")\n","Dataset is MNIST: <class 'torchvision.datasets.mnist.MNIST'>\n","Using downloaded and verified file: ./data/train_32x32.mat\n","Dataset is SVHN: <class 'torchvision.datasets.svhn.SVHN'>\n","Compose(\n","    Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=True)\n","    Grayscale(num_output_channels=3)\n","    ToTensor()\n","    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",")\n","Using downloaded and verified file: ./data/test_32x32.mat\n","Dataset is SVHN: <class 'torchvision.datasets.svhn.SVHN'>\n","MNIST train subset size: 3200\n"]}],"source":["# Function to load and preprocess datasets\n","def load_dataset(dataset_cls, split, root, download, normalize=False, subset_size=None, batch_size=params['batch_size']):\n","    if dataset_cls == datasets.MNIST:\n","        dataset = dataset_cls(root=root, train=(split=='train'), download=download, transform=transforms.ToTensor())\n","    else:\n","        dataset = dataset_cls(root=root, split=split, download=download, transform=transforms.ToTensor())\n","\n","    if normalize:\n","        # mean, std = compute_mean_and_std(dataset)\n","\n","        if dataset_cls == datasets.MNIST:\n","\n","            print(f\"Dataset is MNIST: {dataset_cls}\")\n","            transform = transforms.Compose([\n","                transforms.Resize(( params['img_size'],params['img_size']) ),\n","                transforms.Grayscale(params['channels']),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.5]*params['channels'], std=[0.5]*params['channels'])\n","            ])\n","        else:\n","            print(f\"Dataset is SVHN: {dataset_cls}\")\n","            transform = transforms.Compose([\n","                transforms.Resize(( params['img_size'],params['img_size'] )),\n","                transforms.Grayscale(params['channels']),\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=[0.5]*params['channels'], std=[0.5]*params['channels'])\n","            ])\n","\n","        # Apply the computed normalization\n","        dataset.transform = transform\n","\n","    if subset_size:\n","        indices = np.random.choice(len(dataset), subset_size, replace=False)\n","        print(dataset.transform)\n","        dataset = Subset(dataset, indices)\n","\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True if split == 'train' else False, num_workers=1)\n","    return loader\n","\n","# Load MNIST datasets\n","mnist_trainloader = load_dataset(datasets.MNIST, 'train', './data/', True, normalize=True,subset_size=params['batch_size']*params['mul'] )\n","mnist_testloader = load_dataset(datasets.MNIST, 'test', './data/', True, normalize=True)\n","\n","# Load SVHN datasets\n","svhn_trainloader = load_dataset(datasets.SVHN, 'train', './data/', True, normalize=True,subset_size=params['batch_size']*params['mul'])\n","svhn_testloader = load_dataset(datasets.SVHN, 'test', './data/', True, normalize=True)\n","\n","# Optionally, load the extra SVHN dataset if needed\n","# svhn_extraloader = load_dataset(datasets.SVHN, 'extra', './data/', True, normalize=True, subset_size=20000)\n","\n","# Verify the sizes of the datasets\n","print(f'MNIST train subset size: {len(mnist_trainloader.dataset)}')\n","# print(f'SVHN train subset size: {len(svhn_trainloader.dataset)}')\n","# print(f'SVHN extra size: {len(svhn_extraloader.dataset)}')\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"4tCuY4xqWRzD","executionInfo":{"status":"ok","timestamp":1718892477372,"user_tz":-180,"elapsed":9122,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"outputs":[],"source":["import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# Define the transformations (same as during training)\n","transform = transforms.Compose([\n","    transforms.Grayscale(3),  # Ensure images are single-channel grayscale\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5]*params['channels'], [0.5]*params['channels'])  # Assuming normalization parameters used during training\n","])\n","\n","# Define the path to the transformed images\n","transformed_images_path = 'transformed_mnist_train'\n","\n","# Create the dataset\n","transformed_dataset = datasets.ImageFolder(root=transformed_images_path, transform=transform)\n","\n","# Create the DataLoader\n","transformed_dataloader = DataLoader(transformed_dataset, batch_size=params['batch_size'], shuffle=True, num_workers=2)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"uamc51aDWRzD","executionInfo":{"status":"ok","timestamp":1718892477372,"user_tz":-180,"elapsed":11,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"outputs":[],"source":["# Define weight initialization function\n","def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Linear\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find(\"BatchNorm\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0.0)\n","\n","# Define Coupled Generators\n","class CoupledGenerators(nn.Module):\n","    def __init__(self):\n","        super(CoupledGenerators, self).__init__()\n","\n","        self.init_size = params['img_size'] // 4\n","        self.fc = nn.Sequential(nn.Linear(params['latent_dim'], 128 * self.init_size ** 2))\n","\n","        self.shared_conv = nn.Sequential(\n","            nn.BatchNorm2d(128),\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(128, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Upsample(scale_factor=2),\n","        )\n","        self.G1 = nn.Sequential(\n","            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, params['channels'], 3, stride=1, padding=1),\n","            nn.Tanh(),\n","        )\n","        self.G2 = nn.Sequential(\n","            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, params['channels'], 3, stride=1, padding=1),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, noise):\n","        out = self.fc(noise)\n","        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n","        img_emb = self.shared_conv(out)\n","        features1 = self.G1[:-1](img_emb)  # Get features before the final Tanh layer\n","        features2 = self.G2[:-1](img_emb)  # Get features before the final Tanh layer\n","        img1 = self.G1[-1](features1)\n","        img2 = self.G2[-1](features2)\n","        return img1, img2, features1, features2\n","\n","# Define the classifier with the correct input dimension\n","class Classifier(nn.Module):\n","    def __init__(self, input_dim, num_classes):\n","        super(Classifier, self).__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(input_dim, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.classifier(x)\n","\n","# Define Coupled Discriminators\n","class CoupledDiscriminators(nn.Module):\n","    def __init__(self):\n","        super(CoupledDiscriminators, self).__init__()\n","\n","        def discriminator_block(in_filters, out_filters, bn=True):\n","            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1)]\n","            if bn:\n","                block.append(nn.BatchNorm2d(out_filters, 0.8))\n","            block.extend([nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)])\n","            return block\n","\n","        self.shared_conv = nn.Sequential(\n","            *discriminator_block(params['channels'], 16, bn=False),\n","            *discriminator_block(16, 32),\n","            *discriminator_block(32, 64),\n","            *discriminator_block(64, 128),\n","        )\n","        # The height and width of downsampled image\n","        ds_size = params['img_size'] // 2 ** 4\n","        self.D1 = nn.Linear(128 * ds_size ** 2, 1)\n","        self.D2 = nn.Linear(128 * ds_size ** 2, 1)\n","\n","    def forward(self, img1, img2):\n","        # Determine validity of first image\n","        out = self.shared_conv(img1)\n","        out = out.view(out.shape[0], -1)\n","        validity1 = self.D1(out)\n","        # Determine validity of second image\n","        out = self.shared_conv(img2)\n","        out = out.view(out.shape[0], -1)\n","        validity2 = self.D2(out)\n","\n","        return validity1, validity2\n","\n","# class CoupledGenerators(nn.Module):\n","#     def __init__(self):\n","#         super(CoupledGenerators, self).__init__()\n","\n","#         self.init_size = params['img_size'] // 4\n","#         self.fc = nn.Sequential(nn.Linear(params['latent_dim'], 128 * self.init_size ** 2))\n","\n","#         self.shared_conv = nn.Sequential(\n","#             nn.BatchNorm2d(128),\n","#             nn.Upsample(scale_factor=2),\n","#             nn.Conv2d(128, 128, 3, stride=1, padding=1),\n","#             nn.BatchNorm2d(128, 0.8),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             nn.Upsample(scale_factor=2),\n","#         )\n","#         self.G1 = nn.Sequential(\n","#             nn.Conv2d(128, 64, 3, stride=1, padding=1),\n","#             nn.BatchNorm2d(64, 0.8),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             nn.Conv2d(64, params['channels'], 3, stride=1, padding=1),\n","#             nn.Tanh(),\n","#         )\n","#         self.G2 = nn.Sequential(\n","#             nn.Conv2d(128, 64, 3, stride=1, padding=1),\n","#             nn.BatchNorm2d(64, 0.8),\n","#             nn.LeakyReLU(0.2, inplace=True),\n","#             nn.Conv2d(64, params['channels'], 3, stride=1, padding=1),\n","#             nn.Tanh(),\n","#         )\n","\n","#     def forward(self, noise):\n","#         out = self.fc(noise)\n","#         out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n","#         img_emb = self.shared_conv(out)\n","#         img1 = self.G1(img_emb)\n","#         img2 = self.G2(img_emb)\n","#         return img1, img2\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mwwNJpGmWRzE","executionInfo":{"status":"ok","timestamp":1718892477372,"user_tz":-180,"elapsed":10,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"e69c485c-22e9-4b3f-e65b-f5f66ecaaa2a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["CoupledDiscriminators(\n","  (shared_conv): Sequential(\n","    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Dropout2d(p=0.25, inplace=False)\n","    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (4): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (6): Dropout2d(p=0.25, inplace=False)\n","    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (8): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (10): Dropout2d(p=0.25, inplace=False)\n","    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (12): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n","    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (14): Dropout2d(p=0.25, inplace=False)\n","  )\n","  (D1): Linear(in_features=512, out_features=1, bias=True)\n","  (D2): Linear(in_features=512, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":9}],"source":["# Loss function\n","adversarial_loss = torch.nn.MSELoss()\n","\n","# Initialize models\n","coupled_generators = CoupledGenerators()\n","coupled_discriminators = CoupledDiscriminators()\n","\n","input_dim = 3 * 32 *32  # Adjust this based on actual size\n","num_classes = 10  # Assuming 10 classes for digits\n","classifier = Classifier(input_dim, num_classes)\n","if cuda:\n","    classifier.cuda()\n","\n","\n","if cuda:\n","    coupled_generators.cuda()\n","    coupled_discriminators.cuda()\n","    classifier.cuda()\n","\n","# Initialize weights\n","coupled_generators.apply(weights_init_normal)\n","coupled_discriminators.apply(weights_init_normal)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"e2DBH305WRzE","executionInfo":{"status":"ok","timestamp":1718892477372,"user_tz":-180,"elapsed":10,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"outputs":[],"source":["# Optimizers\n","optimizer_G = torch.optim.Adam(coupled_generators.parameters(), lr=params['lr'], betas=(params['b1'], params['b2']))\n","optimizer_D = torch.optim.SGD(coupled_discriminators.parameters(), lr=params['lr'])\n","optimizer_C = torch.optim.Adam(classifier.parameters(), lr=params['lr'], betas=(params['b1'], params['b2']))\n","\n","\n","Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505},"id":"DRzAgUv8WRzF","executionInfo":{"status":"error","timestamp":1718892512084,"user_tz":-180,"elapsed":34721,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"b78effaa-2a31-4741-a909-a99520306a87"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-e6b88fc41d01>:16: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n","  valid = Variable(Tensor(batch_size, 1).fill_(1.0), requires_grad=False)\n","/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-e6b88fc41d01>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0moptimizer_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."]}],"source":["# ----------\n","#  Training\n","# ----------\n","\n","dataloader1 = mnist_trainloader\n","dataloader2 = svhn_trainloader\n","\n","# Training\n","EPOCHS = 40\n","for epoch in range(EPOCHS):\n","    for i, ((imgs1, labels1), (imgs2, _)) in enumerate(zip(transformed_dataloader, svhn_trainloader)):\n","\n","        batch_size = imgs1.shape[0]\n","\n","        # Adversarial ground truths\n","        valid = Variable(Tensor(batch_size, 1).fill_(1.0), requires_grad=False)\n","        fake = Variable(Tensor(batch_size, 1).fill_(0.0), requires_grad=False)\n","\n","        # Configure input\n","        imgs1 = Variable(imgs1.type(Tensor).expand(imgs1.size(0), 3, params['img_size'], params['img_size']))\n","        imgs2 = Variable(imgs2.type(Tensor))\n","\n","        # ------------------\n","        # Train Generators\n","        # ------------------\n","        optimizer_G.zero_grad()\n","\n","        # Sample noise as generator input\n","        z = Variable(Tensor(np.random.normal(0, 1, (batch_size, params['latent_dim']))))\n","\n","        # Generate a batch of images\n","        gen_imgs1, gen_imgs2, features1, features2 = coupled_generators(z)\n","        # Determine validity of generated images\n","        validity1, validity2 = coupled_discriminators(gen_imgs1, gen_imgs2)\n","\n","        g_loss = (adversarial_loss(validity1, valid) + adversarial_loss(validity2, valid)) / 2\n","\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","        # ------------------\n","        # Train Classifier\n","        # ------------------\n","        optimizer_C.zero_grad()\n","\n","        # Extract features from the generator for source domain\n","        features1_c = features1.view(features1.size(0), -1)  # Flatten features\n","\n","        # Train classifier on source domain features\n","        labels1 = Variable(labels1.type(torch.LongTensor).cuda())\n","        outputs = classifier(features1_c)\n","        c_loss = F.cross_entropy(outputs, labels1)\n","\n","        c_loss.backward()\n","        optimizer_C.step()\n","\n","\n","        # ------------------\n","        # Train Discriminators\n","        # ------------------\n","        optimizer_D.zero_grad()\n","\n","        # Determine validity of real and generated images\n","        validity1_real, validity2_real = coupled_discriminators(imgs1, imgs2)\n","        validity1_fake, validity2_fake = coupled_discriminators(gen_imgs1.detach(), gen_imgs2.detach())\n","\n","        d_loss = (\n","            adversarial_loss(validity1_real, valid)\n","            + adversarial_loss(validity1_fake, fake)\n","            + adversarial_loss(validity2_real, valid)\n","            + adversarial_loss(validity2_fake, fake)\n","        ) / 4\n","\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","\n","\n","        print(\n","            f\"[Epoch {epoch}/{EPOCHS}] [Batch {i}/{len(mnist_trainloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}] [C loss: {c_loss.item()}]\"\n","        )\n","\n","        batches_done = epoch * len(mnist_trainloader) + i\n","        if batches_done % 100 == 0:\n","            gen_imgs = torch.cat((gen_imgs1.data, gen_imgs2.data), 0)\n","            save_image(gen_imgs, f\"coGAN_img/{batches_done}_.png\", nrow=8, normalize=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tKG4McCgWRzF","executionInfo":{"status":"aborted","timestamp":1718892512085,"user_tz":-180,"elapsed":2,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","\n","# Define the Generator\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.fc = nn.Sequential(\n","            nn.Linear(100, 256),\n","            nn.ReLU(True),\n","            nn.Linear(256, 512),\n","            nn.ReLU(True),\n","            nn.Linear(512, 1024),\n","            nn.ReLU(True),\n","            nn.Linear(1024, 3*32*32),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        return self.fc(x).view(-1, 3, 32, 32)\n","\n","# Define the shared part of the Discriminator\n","class SharedDiscriminator(nn.Module):\n","    def __init__(self):\n","        super(SharedDiscriminator, self).__init__()\n","        self.shared_layers = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","\n","    def forward(self, x):\n","        return self.shared_layers(x)\n","\n","# Define the Discriminator with domain-specific and classification heads\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.shared = SharedDiscriminator()\n","        self.domain_head = nn.Sequential(\n","            nn.Linear(128 * 8 * 8, 1024),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(1024, 1),\n","            nn.Sigmoid()\n","        )\n","        self.classifier_head = nn.Sequential(\n","            nn.Linear(128 * 8 * 8, 1024),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Linear(1024, 10),\n","            nn.LogSoftmax(dim=1)\n","        )\n","\n","    def forward(self, x):\n","        shared_features = self.shared(x).view(-1, 128 * 8 * 8)\n","        domain_output = self.domain_head(shared_features)\n","        classification_output = self.classifier_head(shared_features)\n","        return domain_output, classification_output\n","# Initialize the models\n","G_A = Generator()\n","G_B = Generator()\n","D_A = Discriminator()\n","D_B = Discriminator()\n","\n","# Loss functions\n","adversarial_loss = nn.BCELoss()\n","classification_loss = nn.NLLLoss()\n","\n","# Optimizers\n","optimizer_G = optim.Adam(list(G_A.parameters()) + list(G_B.parameters()), lr=0.0002, betas=(0.5, 0.999))\n","optimizer_D_A = optim.SGD(D_A.parameters(), lr=0.00002)\n","optimizer_D_B = optim.SGD(D_B.parameters(), lr=0.00002)\n","\n","n_epoch = 20\n","# Training loop\n","for epoch in range(n_epoch):\n","    for (mnist_imgs, mnist_labels), (svhn_imgs, _) in zip(mnist_trainloader, svhn_trainloader):\n","        batch_size = mnist_imgs.size(0)\n","\n","        # Adversarial ground truths\n","        valid = torch.ones(batch_size, 1)\n","        fake = torch.zeros(batch_size, 1)\n","\n","        # ---------------------\n","        #  Train Generators\n","        # ---------------------\n","\n","        optimizer_G.zero_grad()\n","\n","        # Sample noise as generator input\n","        z = torch.randn(batch_size, 100)\n","\n","        # Generate a batch of images\n","        gen_mnist = G_A(z)\n","        gen_svhn = G_B(z)\n","\n","        # Loss measures generator's ability to fool the discriminator\n","        validity_A, _ = D_A(gen_mnist)\n","        validity_B, _ = D_B(gen_svhn)\n","        g_loss = adversarial_loss(validity_A, valid) + adversarial_loss(validity_B, valid)\n","\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","        # ---------------------\n","        #  Train Discriminators\n","        # ---------------------\n","\n","        optimizer_D_A.zero_grad()\n","\n","        # Measure discriminator's ability to classify real from generated samples\n","        real_pred, _ = D_A(mnist_imgs)\n","        fake_pred, _ = D_A(gen_mnist.detach())\n","        d_loss_A = adversarial_loss(real_pred, valid) + adversarial_loss(fake_pred, fake)\n","\n","        d_loss_A.backward()\n","        optimizer_D_A.step()\n","\n","        optimizer_D_B.zero_grad()\n","\n","        # Measure discriminator's ability to classify real from generated samples\n","        real_pred, _ = D_B(svhn_imgs)\n","        fake_pred, _ = D_B(gen_svhn.detach())\n","        d_loss_B = adversarial_loss(real_pred, valid) + adversarial_loss(fake_pred, fake)\n","\n","        d_loss_B.backward()\n","        optimizer_D_B.step()\n","\n","        # ---------------------\n","        #  Train Classifiers\n","        # ---------------------\n","\n","        _, mnist_class_pred = D_A(mnist_imgs)\n","        c_loss = classification_loss(mnist_class_pred, mnist_labels)\n","\n","        c_loss.backward()\n","        optimizer_D_A.step()\n","\n","    print(f\"Epoch {epoch}/{n_epoch} - G Loss: {g_loss.item()} - D_A Loss: {d_loss_A.item()} - D_B Loss: {d_loss_B.item()} - C Loss: {c_loss.item()}\")\n","\n","# Ensure the model is in evaluation mode\n","D_B.eval()\n","\n","with torch.no_grad():\n","    # Evaluate on SVHN test set\n","    for svhn_imgs, svhn_labels in svhn_testloader:\n","        svhn_imgs, svhn_labels = svhn_imgs.to(DEVICE), svhn_labels.to(DEVICE)\n","        _, svhn_class_pred = D_B(svhn_imgs)\n","        _, predicted_svhn = torch.max(svhn_class_pred, 1)\n","        total_svhn += svhn_labels.size(0)\n","        correct_svhn += (predicted_svhn == svhn_labels).sum().item()\n","\n","    # Evaluate on MNIST test set\n","    for mnist_imgs, mnist_labels in mnist_testloader:\n","        mnist_imgs, mnist_labels = mnist_imgs.to(DEVICE), mnist_labels.to(DEVICE)\n","        _, mnist_class_pred = D_B(mnist_imgs)\n","        _, predicted_mnist = torch.max(mnist_class_pred, 1)\n","        total_mnist += mnist_labels.size(0)\n","        correct_mnist += (predicted_mnist == mnist_labels).sum().item()\n","\n","# Calculate accuracy\n","accuracy_svhn = 100 * correct_svhn / total_svhn\n","accuracy_mnist = 100 * correct_mnist / total_mnist\n","\n","# Print results\n","print(f'SVHN Test Accuracy: {accuracy_svhn:.2f}% ({correct_svhn}/{total_svhn})')\n","print(f'MNIST Test Accuracy: {accuracy_mnist:.2f}% ({correct_mnist}/{total_mnist})')\n","\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define weight initialization function\n","def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Linear\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find(\"BatchNorm\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0.0)\n","\n","params = {\n","    'img_size': 32,\n","    'latent_dim': 100,\n","    'channels': 3\n","}\n","\n","# Define Coupled Generators\n","class CoupledGenerators(nn.Module):\n","    def __init__(self):\n","        super(CoupledGenerators, self).__init__()\n","\n","        self.init_size = params['img_size'] // 4\n","        self.fc = nn.Sequential(nn.Linear(params['latent_dim'], 128 * self.init_size ** 2))\n","\n","        self.shared_conv = nn.Sequential(\n","            nn.BatchNorm2d(128),\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(128, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Upsample(scale_factor=2),\n","        )\n","        self.G1 = nn.Sequential(\n","            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, params['channels'], 3, stride=1, padding=1),\n","            nn.Dropout(0.3),\n","            nn.Tanh(),\n","        )\n","        self.G2 = nn.Sequential(\n","            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, params['channels'], 3, stride=1, padding=1),\n","            nn.Dropout(0.3),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, noise):\n","        out = self.fc(noise)\n","        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n","        img_emb = self.shared_conv(out)\n","        features1 = self.G1[:-1](img_emb)  # Get features before the final Tanh layer\n","        features2 = self.G2[:-1](img_emb)  # Get features before the final Tanh layer\n","        img1 = self.G1[-1](features1)\n","        img2 = self.G2[-1](features2)\n","        return img1, img2, features1, features2\n","\n","# Define the classifier with the correct input dimension\n","class Classifier(nn.Module):\n","    def __init__(self, input_dim, num_classes):\n","        super(Classifier, self).__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(input_dim, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.classifier(x)\n","\n","# Define Coupled Discriminators\n","class CoupledDiscriminators(nn.Module):\n","    def __init__(self):\n","        super(CoupledDiscriminators, self).__init__()\n","\n","        def discriminator_block(in_filters, out_filters, bn=True):\n","            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1)]\n","            if bn:\n","                block.append(nn.BatchNorm2d(out_filters, 0.8))\n","            block.extend([nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)])\n","            return block\n","\n","        self.shared_conv = nn.Sequential(\n","            *discriminator_block(params['channels'], 64, bn=False),\n","            *discriminator_block(64, 128),\n","            *discriminator_block(128, 256),\n","            *discriminator_block(256, 512),\n","        )\n","        # The height and width of downsampled image\n","        ds_size = params['img_size'] // 2 ** 4\n","        self.D1 = nn.Sequential(\n","            nn.Linear(512 * ds_size ** 2, 1),\n","            nn.Sigmoid()  # Add sigmoid activation\n","        )\n","        self.D2 = nn.Sequential(\n","            nn.Linear(512 * ds_size ** 2, 1),\n","            nn.Sigmoid()  # Add sigmoid activation\n","        )\n","        self.C1 = nn.Linear(512 * ds_size ** 2, 10)\n","        self.C2 = nn.Linear(512 * ds_size ** 2, 10)\n","\n","    def forward(self, img1, img2):\n","        # Determine validity of first image\n","        out1 = self.shared_conv(img1)\n","        out1 = out1.view(out1.shape[0], -1)\n","        validity1 = self.D1(out1)\n","        class1 = self.C1(out1)\n","\n","        # Determine validity of second image\n","        out2 = self.shared_conv(img2)\n","        out2 = out2.view(out2.shape[0], -1)\n","        validity2 = self.D2(out2)\n","        class2 = self.C2(out2)\n","\n","        return validity1, validity2, class1, class2\n","\n","# Initialize the models\n","G = CoupledGenerators()\n","D = CoupledDiscriminators()\n","\n","# Apply weight initialization\n","G.apply(weights_init_normal)\n","D.apply(weights_init_normal)\n","\n","# Loss functions\n","adversarial_loss = nn.BCELoss()\n","classification_loss = nn.CrossEntropyLoss()\n","\n","# Optimizers\n","optimizer_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizer_D = optim.SGD(D.parameters(), lr=0.0002)\n","\n","\n","# Training loop\n","for epoch in range(10):\n","    for (mnist_imgs, mnist_labels), (svhn_imgs, _) in zip(mnist_trainloader, svhn_trainloader):\n","        batch_size = mnist_imgs.size(0)\n","\n","        # Adversarial ground truths\n","        valid = torch.ones(batch_size, 1)\n","        fake = torch.zeros(batch_size, 1)\n","\n","        # ---------------------\n","        #  Train Generators\n","        # ---------------------\n","\n","        optimizer_G.zero_grad()\n","\n","        # Sample noise as generator input\n","        z = torch.randn(batch_size, params['latent_dim'])\n","\n","        # Generate a batch of images\n","        gen_mnist, gen_svhn, features_mnist, features_svhn = G(z)\n","\n","        # Loss measures generator's ability to fool the discriminator\n","        validity_mnist, validity_svhn, _, _ = D(gen_mnist, gen_svhn)\n","        g_loss = adversarial_loss(validity_mnist, valid) + adversarial_loss(validity_svhn, valid)\n","\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","        # ---------------------\n","        #  Train Discriminators\n","        # ---------------------\n","\n","        optimizer_D.zero_grad()\n","\n","        # Measure discriminator's ability to classify real from generated samples\n","        real_pred_mnist, real_pred_svhn, class_pred_mnist, _ = D(mnist_imgs, svhn_imgs)\n","        fake_pred_mnist, fake_pred_svhn, _, _ = D(gen_mnist.detach(), gen_svhn.detach())\n","\n","        d_loss_real = adversarial_loss(real_pred_mnist, valid) + adversarial_loss(real_pred_svhn, valid)\n","        d_loss_fake = adversarial_loss(fake_pred_mnist, fake) + adversarial_loss(fake_pred_svhn, fake)\n","        d_loss = (d_loss_real + d_loss_fake) / 2\n","\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        # ---------------------\n","        #  Train Classifiers\n","        # ---------------------\n","\n","        optimizer_D.zero_grad()\n","\n","        class_pred_mnist, _ = D(mnist_imgs, svhn_imgs)[2:]\n","        c_loss = classification_loss(class_pred_mnist, mnist_labels)\n","\n","        c_loss.backward()\n","        optimizer_D.step()\n","\n","    print(f\"Epoch {epoch}/{10} - G Loss: {g_loss.item()} - D Loss: {d_loss.item()} - C Loss: {c_loss.item()}\")\n","\n","# Initialize variables for tracking accuracy\n","correct_svhn = 0\n","total_svhn = 0\n","correct_mnist = 0\n","total_mnist = 0\n","\n","# Ensure the model is in evaluation mode\n","D.eval()\n","\n","with torch.no_grad():\n","    # Evaluate on SVHN test set\n","    for svhn_imgs, svhn_labels in svhn_testloader:\n","        svhn_imgs, svhn_labels = svhn_imgs.to(DEVICE), svhn_labels.to(DEVICE)\n","        _, svhn_class_pred = D(svhn_imgs,torch.zeros_like(svhn_imgs))\n","        _, predicted_svhn = torch.max(svhn_class_pred, 1)\n","        total_svhn += svhn_labels.size(0)\n","        correct_svhn += (predicted_svhn == svhn_labels).sum().item()\n","\n","    # Evaluate on MNIST test set\n","    for mnist_imgs, mnist_labels in mnist_testloader:\n","        mnist_imgs, mnist_labels = mnist_imgs.to(DEVICE), mnist_labels.to(DEVICE)\n","        _, mnist_class_pred = D(mnist_imgs,torch.zeros_like(mnist_imgs))\n","        _, predicted_mnist = torch.max(mnist_class_pred, 1)\n","        total_mnist += mnist_labels.size(0)\n","        correct_mnist += (predicted_mnist == mnist_labels).sum().item()\n","\n","# Calculate accuracy\n","accuracy_svhn = 100 * correct_svhn / total_svhn\n","accuracy_mnist = 100 * correct_mnist / total_mnist\n","\n","# Print results\n","print(f'SVHN Test Accuracy: {accuracy_svhn:.2f}% ({correct_svhn}/{total_svhn})')\n","print(f'MNIST Test Accuracy: {accuracy_mnist:.2f}% ({correct_mnist}/{total_mnist})')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":559},"id":"fW-YmgAJ_rK8","executionInfo":{"status":"error","timestamp":1718895908725,"user_tz":-180,"elapsed":413387,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"b2c24c74-ddce-4730-c5fc-4571cc8ef621"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/10 - G Loss: 1.2886850833892822 - D Loss: 1.4369761943817139 - C Loss: 2.3049843311309814\n","Epoch 1/10 - G Loss: 1.2301700115203857 - D Loss: 1.4619617462158203 - C Loss: 2.293734312057495\n","Epoch 2/10 - G Loss: 1.1831457614898682 - D Loss: 1.4919672012329102 - C Loss: 2.3105039596557617\n","Epoch 3/10 - G Loss: 1.1616599559783936 - D Loss: 1.5028189420700073 - C Loss: 2.3045589923858643\n","Epoch 4/10 - G Loss: 1.1548199653625488 - D Loss: 1.5147151947021484 - C Loss: 2.30519700050354\n","Epoch 5/10 - G Loss: 1.1470779180526733 - D Loss: 1.515200138092041 - C Loss: 2.296841859817505\n","Epoch 6/10 - G Loss: 1.1428532600402832 - D Loss: 1.5149661302566528 - C Loss: 2.288012981414795\n","Epoch 7/10 - G Loss: 1.1464552879333496 - D Loss: 1.5161023139953613 - C Loss: 2.2940988540649414\n","Epoch 8/10 - G Loss: 1.1589207649230957 - D Loss: 1.506476640701294 - C Loss: 2.2968218326568604\n","Epoch 9/10 - G Loss: 1.1611943244934082 - D Loss: 1.5087745189666748 - C Loss: 2.305819511413574\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-ab1c5ae674c6>\u001b[0m in \u001b[0;36m<cell line: 211>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msvhn_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvhn_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msvhn_testloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0msvhn_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvhn_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvhn_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvhn_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvhn_class_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvhn_imgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvhn_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_svhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvhn_class_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mtotal_svhn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msvhn_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-ab1c5ae674c6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img1, img2)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Determine validity of first image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mvalidity1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tqoQ3E82-00Q"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}