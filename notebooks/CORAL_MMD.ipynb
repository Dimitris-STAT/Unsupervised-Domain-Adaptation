{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install torch\n",
    "# %pip install torchvision==0.17\n",
    "# %pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary of arguments\n",
    "args = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'batch_size': 64,\n",
    "    'num_classes': 10,\n",
    "    'num_epochs': 5,\n",
    "    'lr': 0.01\n",
    "}\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224,224) ),\n",
    "                                transforms.Grayscale(num_output_channels=3), # Convert to 3-channel\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                                ])\n",
    "\n",
    "# Define the batch size\n",
    "mnist_batch_size = args['batch_size']\n",
    "\n",
    "# Load the MNIST training dataset\n",
    "mnist_trainset = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the MNIST training dataset\n",
    "mnist_trainloader = torch.utils.data.DataLoader(\n",
    "    mnist_trainset,\n",
    "    batch_size=mnist_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Load the MNIST test dataset\n",
    "mnist_testset = torchvision.datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the MNIST test dataset\n",
    "mnist_testloader = torch.utils.data.DataLoader(\n",
    "    mnist_testset,\n",
    "    batch_size=mnist_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "# Define the transformation with ToTensor and Normalize for SVHN\n",
    "svhn_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Define the batch size\n",
    "svhn_batch_size = args['batch_size']\n",
    "\n",
    "# Load the SVHN training dataset\n",
    "svhn_trainset = torchvision.datasets.SVHN(\n",
    "    root='./data/',\n",
    "    split='train',\n",
    "    download=True,\n",
    "    transform=svhn_transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the SVHN training dataset\n",
    "svhn_trainloader = torch.utils.data.DataLoader(\n",
    "    svhn_trainset,\n",
    "    batch_size=svhn_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Load the SVHN test dataset\n",
    "svhn_testset = torchvision.datasets.SVHN(\n",
    "    root='./data/',\n",
    "    split='test',\n",
    "    download=True,\n",
    "    transform=svhn_transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the SVHN test dataset\n",
    "svhn_testloader = torch.utils.data.DataLoader(\n",
    "    svhn_testset,\n",
    "    batch_size=svhn_batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# # Optionally, load the extra dataset if needed\n",
    "# svhn_extraset = torchvision.datasets.SVHN(\n",
    "#     root='./data/',\n",
    "#     split='extra',\n",
    "#     download=True,\n",
    "#     transform=svhn_transform\n",
    "# )\n",
    "\n",
    "# # Create a DataLoader for the SVHN extra dataset\n",
    "# svhn_extraloader = torch.utils.data.DataLoader(\n",
    "#     svhn_extraset,\n",
    "#     batch_size=svhn_batch_size,\n",
    "#     shuffle=True,\n",
    "#     num_workers=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMD calculation (MNIST vs SVHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD value between MNIST and SVHN: 0.03125\n"
     ]
    }
   ],
   "source": [
    "# Define the Gaussian(RBF) kernel function\n",
    "def gaussian_kernel(x, y, sigma=1.0):\n",
    "    return torch.exp(-torch.sum((x - y) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "# Compute MMD\n",
    "def compute_mmd(x, y, kernel=gaussian_kernel, sigma=1.0):\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    \n",
    "    xx_kernel_sum = torch.sum(torch.tensor([kernel(xi, xj, sigma) for xi in x for xj in x])).item() / (n * n)\n",
    "    yy_kernel_sum = torch.sum(torch.tensor([kernel(yi, yj, sigma) for yi in y for yj in y])).item() / (m * m)\n",
    "    xy_kernel_sum = torch.sum(torch.tensor([kernel(xi, yj, sigma) for xi in x for yj in y])).item() / (n * m)\n",
    "    \n",
    "    return xx_kernel_sum + yy_kernel_sum - 2 * xy_kernel_sum\n",
    "\n",
    "# Get samples from the loaders\n",
    "mnist_samples, _ = next(iter(mnist_trainloader))\n",
    "svhn_samples, _ = next(iter(svhn_trainloader))z\n",
    "\n",
    "# Compute MMD\n",
    "mmd_value = compute_mmd(mnist_samples, svhn_samples)\n",
    "print(f'MMD value between MNIST and SVHN: {mmd_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(mnist_samples[i].permute(1, 2, 0).numpy() / 2 + 0.5)\n",
    "    ax.set_title('MNIST')\n",
    "    ax.axis('off')\n",
    "\n",
    "# SVHN samples\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(svhn_samples[i].permute(1, 2, 0).numpy() / 2 + 0.5)\n",
    "    ax.set_title('SVHN')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORAL implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2578054119424 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 92\u001b[0m\n\u001b[0;32m     89\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(simpleNN\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m train_model(simpleNN, mnist_trainloader, svhn_trainloader, \u001b[38;5;28;01mNone\u001b[39;00m, coral_criterion, optimizer, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[4], line 68\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, source_loader, target_loader, criterion, coral_criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     65\u001b[0m target_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeatures(target_images)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Compute CORAL loss\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m coral_loss \u001b[38;5;241m=\u001b[39m coral_criterion(source_features\u001b[38;5;241m.\u001b[39mview(source_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     69\u001b[0m                              target_features\u001b[38;5;241m.\u001b[39mview(target_features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Compute classification loss (if you have labels)\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# class_loss = criterion(source_predictions, source_labels)\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Combine losses\u001b[39;00m\n\u001b[0;32m     75\u001b[0m loss \u001b[38;5;241m=\u001b[39m coral_loss  \u001b[38;5;66;03m# + class_loss (if using classification loss)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stath\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\stath\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m, in \u001b[0;36mCORAL.forward\u001b[1;34m(self, source, target)\u001b[0m\n\u001b[0;32m      6\u001b[0m d \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Compute covariance matrices\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m source_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_matrix(source)\n\u001b[0;32m     10\u001b[0m target_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_matrix(target)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Compute the CORAL loss\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m, in \u001b[0;36mCORAL.covariance_matrix\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m x_centered \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m cov \u001b[38;5;241m=\u001b[39m (x_centered\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m@\u001b[39m x_centered) \u001b[38;5;241m/\u001b[39m (n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cov\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2578054119424 bytes."
     ]
    }
   ],
   "source": [
    "class CORAL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CORAL, self).__init__()\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        d = source.size(1)\n",
    "\n",
    "        # Compute covariance matrices\n",
    "        source_c = self.covariance_matrix(source)\n",
    "        target_c = self.covariance_matrix(target)\n",
    "\n",
    "        # Compute the CORAL loss\n",
    "        loss = self.coral_loss(source_c, target_c, d)\n",
    "        return loss\n",
    "\n",
    "    def covariance_matrix(self, x):\n",
    "        n = x.size(0)\n",
    "        x_centered = x - x.mean(0)\n",
    "        cov = (x_centered.t() @ x_centered) / (n - 1)\n",
    "        return cov\n",
    "\n",
    "    def coral_loss(self, source_c, target_c, d):\n",
    "        # Frobenius norm of the difference between the covariance matrices\n",
    "        loss = torch.norm(source_c - target_c, p='fro') ** 2\n",
    "        # Normalize by the dimensionality of the feature space\n",
    "        loss = loss / (4 * d * d)\n",
    "        return loss\n",
    "\n",
    "# Define your neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Add more layers as needed\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 16 * 16, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, source_loader, target_loader, criterion, coral_criterion, optimizer, device):\n",
    "    model.train()\n",
    "\n",
    "    for i, ((source_images, _), (target_images, _)) in enumerate(zip(source_loader, target_loader)):\n",
    "        source_images = source_images.to(device)\n",
    "        target_images = target_images.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        source_features = model.features(source_images)\n",
    "        target_features = model.features(target_images)\n",
    "\n",
    "        # Compute CORAL loss\n",
    "        coral_loss = coral_criterion(source_features.view(source_features.size(0), -1),\n",
    "                                     target_features.view(target_features.size(0), -1))\n",
    "\n",
    "        # Compute classification loss (if you have labels)\n",
    "        # class_loss = criterion(source_predictions, source_labels)\n",
    "\n",
    "        # Combine losses\n",
    "        loss = coral_loss  # + class_loss (if using classification loss)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Batch [{i + 1}], CORAL Loss: {coral_loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Instantiate the model, criterion, and optimizer\n",
    "simpleNN = SimpleNN().to(args['device'])\n",
    "coral_criterion = CORAL().to(args['device'])\n",
    "optimizer = optim.Adam(simpleNN.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(simpleNN, mnist_trainloader, svhn_trainloader, None, coral_criterion, optimizer, args['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
